<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Pratik  Kunapuli


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü§ñ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Pratik</span>  Kunapuli
    </h1>
     <p class="desc"><strong>Ph.D. Student</strong>, University of Pennsylvania</p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>I‚Äôm a doctoral student in Computer and Information Science (CIS) at <a href="https://www.grasp.upenn.edu/" target="_blank" rel="noopener noreferrer">GRASP</a> at the University of Pennsylvania. I am co-advised by <a href="https://www.kumarrobotics.org/" target="_blank" rel="noopener noreferrer">Vijay Kumar</a> and <a href="https://www.seas.upenn.edu/~dineshj/" target="_blank" rel="noopener noreferrer">Dinesh Jayaraman</a>, and am grateful to be supported by the NSF as a <a href="https://www.nsfgrfp.org/" target="_blank" rel="noopener noreferrer">GRFP</a> Fellow. My research interests lie at the intersection of machine learning and robotics, specifically related to using reinforcement learning for control of agile and dynamic systems as well as transferring learning approaches from simulation to the real world (sim2real).</p>

<p>Previously, I completed both my BSc and MSc at Georgia Institute of Technology in Electrical and Computer Engineering. During my time there, I worked with <a href="https://www.me.gatech.edu/faculty/young" target="_blank" rel="noopener noreferrer">Aaron Young</a> in the <a href="http://www.epic.gatech.edu/" target="_blank" rel="noopener noreferrer">Exoskeleton Prosthetic Intelligent Controls Lab (EPIC Lab)</a> initially developing controllers for a powered knee and ankle prosthetic and eventually applying machine learning-based state estimation to autonomous hip exoskeletons. My work culminated in my Masters thesis, ‚ÄúOnline Adaptation of User State Estimation in a Powered Hip Exoskeleton using Machine Learning‚Äù.</p>

<p><a href="/assets/pdf/Pratik_Kunapuli_CV.pdf">Curriculum Vitae</a></p>

    </div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">BMES ABME</abbr>
    
  
  </div>

  <div id="maldonado2023user" class="col-sm-8">
    
      <div class="title">User-and Speed-Independent Slope Estimation for Lower-Extremity Wearable Robots</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Maldonado-Contreras, Jairo Y,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bhakta, Krishan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Camargo, Jonathan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kunapuli, Pratik</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Young, Aaron J
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Annals of Biomedical Engineering</em>
      
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://link.springer.com/article/10.1007/s10439-023-03391-y" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/maldonado2023user-independent.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Wearable robots can help users traverse unstructured slopes by providing mode-specific hip, knee, and ankle joint assistance. However, generalizing the same assistance pattern across different slopes is not optimal. Control strategies that scale assistance based on slope are expected to improve the feel of the device and improve outcome measures such as decreasing metabolic cost. Prior numerical methods for slope estimation struggled to estimate slopes at variable walking speeds or were limited to a single estimation per gait cycle. This study overcomes these limitations by developing machine-learning methods that yield continuous, user- and speed-independent slope estimators for a variety of wearable robot applications using an able-bodied wearable sensor dataset. In a leave-one-subject-out cross-validation (N‚Äâ=‚Äâ9), four-phase XGBoost regression models were trained on static-slope (fixed-slope) data and evaluated on a novel subject‚Äôs static-slope and dynamic-slope (variable-slope) data. Using all available sensors, we achieved an average error of 0.88¬∞ and 1.73¬∞ mean absolute error (MAE) on static and dynamic slopes, respectively. Ankle prosthesis, knee-ankle prosthesis, and hip exoskeleton sensor suites yielded average errors under 2¬∞ MAE on static and dynamic slopes, except for the ankle prosthesis and hip exoskeleton cases on dynamic slopes which yielded an average error of 2.2¬∞ and 3.2¬∞ MAE, respectively. We found that the thigh inertial measurement unit contributed the most to a reduction in average error. Our findings suggest that reliable slope estimators can be trained using only static-slope data regardless of the type of lower-extremity wearable robot.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE RAL</abbr>
    
  
  </div>

  <div id="kang2021realtime" class="col-sm-8">
    
      <div class="title">Real-Time Gait Phase Estimation for Robotic Hip Exoskeleton Control During Multimodal Locomotion</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Kang, Inseung,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Molinaro, Dean D.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Duggal, Srijan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chen, Yanrong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kunapuli, Pratik</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Young, Aaron J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Robotics and Automation Letters</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/9364364" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/kang2021realtime.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We developed and validated a gait phase estimator for real-time control of a robotic hip exoskeleton during multimodal locomotion. Gait phase describes the fraction of time passed since the previous gait event, such as heel strike, and is a promising framework for appropriately applying exoskeleton assistance during cyclic tasks. A conventional method utilizes a mechanical sensor to detect a gait event and uses the time since the last gait event to linearly interpolate the current gait phase. While this approach may work well for constant treadmill walking, it shows poor performance when translated to overground situations where the user may change walking speed and locomotion modes dynamically. To tackle these challenges, we utilized a convolutional neural network-based gait phase estimator that can adapt to different locomotion mode settings to modulate the exoskeleton assistance. Our resulting model accurately predicted the gait phase during multimodal locomotion without any additional information about the user‚Äôs locomotion mode, with a gait phase estimation RMSE of 5.04 ¬± 0.79%, significantly outperforming the literature standard (p &lt;; 0.05). Our study highlights the promise of translating exoskeleton technology to more realistic settings where the user can naturally and seamlessly navigate through different terrain settings.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE TMRB</abbr>
    
  
  </div>

  <div id="kang2020realtime" class="col-sm-8">
    
      <div class="title">Real-Time Neural Network-Based Gait Phase Estimation Using a Robotic Hip Exoskeleton</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Kang, Inseung*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kunapuli, Pratik*</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Young, Aaron J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Medical Robotics and Bionics</em>
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/8941004" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/kang2020realtime.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Lower limb exoskeletons provide assistance during the gait cycle using a state variable, one in particular is gait phase. This is crucial for the exoskeleton controller to provide the user accurate assistance. Conventional methods often utilize an event marker to estimate gait phase by computing the average stride time. However, this strategy has limitations in adapting to dynamic speeds. We developed a sensor fusion-based neural network model to estimate the gait phase in real-time that can adapt to dynamic speeds ranging from 0.6 to 1.1 m/s. Ten able-bodied subjects walked with an exoskeleton using our estimator and were provided with corresponding torque assistance. Our best performing model had RMSE below 29 ms and 4% for real-time estimation and torque generation, respectively, reducing the estimation error by 36.0% (p &lt; 0.01) and torque error by 40.9% (p &lt; 0.001) compared to conventional methods. Our results indicate that creating a general user-independent model and additionally training on user-specific data outperforms the user-specific model and user-independent model. Our study validates the feasibility of using a sensor fusion-based machine learning model to accurately estimate the user‚Äôs gait phase and improve the controllability of a lower limb exoskeleton.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICORR</abbr>
    
  
  </div>

  <div id="kang2019electromyography" class="col-sm-8">
    
      <div class="title">Electromyography (EMG) Signal Contributions in Speed and Slope Estimation Using Robotic Exoskeletons</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Kang, Inseung,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kunapuli, Pratik</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hsu, Hsiang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Young, Aaron J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/8779433" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/kang2019electromyography.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Robotic exoskeletons have the capability to improve community ambulation in aging individuals. These exoskeleton controllers utilize different environmental information such as walking speeds and slope inclines to provide corresponding assistance. Several numerical approaches for estimating this environmental information have been implemented; however, they tend to be limited during dynamic changes. A possible solution is a machine learning model utilizing the user‚Äôs electromyography (EMG) signals along with mechanical sensor data. We developed a neural network-based walking speed and slope estimator for a powered hip exoskeleton and explored the EMG signal contributions in both static and dynamic settings while wearing the device. We also analyzed the performance of different EMG electrode placements. The resulting machine learning model achieved error rates below 0.08 m/s RMSE and 1.3 RMSE. Our study findings from four able-bodied and two elderly subjects indicate that EMG can improve the performance by reducing the error rate by 14.8% compared to the model using only mechanical sensors. Additionally, results show that using EMG electrode configuration within the exoskeleton interface region is sufficient for the EMG model performance.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MIL MED</abbr>
    
  
  </div>

  <div id="bhakta2019impedance" class="col-sm-8">
    
      <div class="title">Impedance Control Strategies for Enhancing Sloped and Level Walking Capabilities for Individuals with Transfemoral Amputation Using a Powered Multi-Joint Prosthesis</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Bhakta, Krishan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Camargo, Jonathan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kunapuli, Pratik</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Childers, Lee,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Young, Aaron
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Military Medicine</em>
      
      
        Dec
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://academic.oup.com/milmed/article/185/Supplement_1/490/5670554?login=true" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/bhakta2019impedance" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Powered prostheses are a promising new technology that may help people with lower-limb loss improve their ability to perform locomotion tasks. Developing active prostheses requires robust design methodologies and intelligent controllers to appropriately provide assistance to the user for varied tasks in different environments. The purpose of this study was to validate an impedance control strategy for a powered knee and ankle prosthesis using an embedded sensor suite of encoders and a six-axis load cell that would aid an individual in performing common locomotion tasks, such as level walking and ascending/descending slopes.Three amputees walked on a treadmill and four amputees walked on a ramp circuit to test whether a dual powered knee and ankle prosthesis could generate appropriate device joint kinematics across users.Investigators found that tuning 2‚Äì3 subject-specific parameters per ambulation mode was necessary to render individualized assistance. Furthermore, the kinematic profiles demonstrate invariance to walking speeds ranging from 0.63 to 1.07 m/s and incline/decline angles ranging from 7.8¬∞ to 14¬∞.This work presents a strategy that requires minimal tuning for a powered knee \&amp; ankle prosthesis that scales across a nominal range of both walking speeds and ramp slopes.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%70%72%61%74%69%6B%6B@%73%65%61%73.%75%70%65%6E%6E.%65%64%75"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=GPJ2qqgAAAAJ&amp;hl=en&amp;oi=ao" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/PratikKunapuli" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>

<a href="https://twitter.com/PKunapuli" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>













      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2023 Pratik  Kunapuli.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

    
    
    Last updated: November 15, 2023.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
